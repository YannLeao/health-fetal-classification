{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b8965de",
   "metadata": {},
   "source": [
    "# Modelagem Parte 1: Árvore de Decisão e KNN \n",
    "\n",
    "Objetivo: Nesta etapa, realizamos o treinamento dos algoritmos Decision Tree e K-Nearest Neighbors (KNN) utilizando o dataset pré-processado de saúde fetal.\n",
    "\n",
    "Metodologia: * Validação: 10-fold Stratified Cross-Validation. * Otimização: GridSearch para encontrar os melhores hiperparâmetros (testando no mínimo 3 combinações).\n",
    "\n",
    "\n",
    "Métricas: Acurácia, Precisão, Recall e F1-Score (weighted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e03f4eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "from modeling import run_classification_experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07a2f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join('..', 'data', 'processed', 'fetal_health_processed.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "X = df.drop('fetal_health', axis=1)\n",
    "y = df['fetal_health']\n",
    "\n",
    "print(\"Dados carregados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08de6263",
   "metadata": {},
   "source": [
    "## 1. Árvore de Decisão (Decision Tree)\n",
    "\n",
    "A árvore de decisão é um modelo interpretável que divide os dados com base em regras de decisão. Para evitar overfitting e encontrar a melhor generalização, testaremos os seguintes hiperparâmetros via GridSearch:\n",
    "\n",
    "Criterion: Gini vs Entropia (qual métrica de pureza funciona melhor).\n",
    "\n",
    "Max Depth: None (sem limite), 10, 20, 30 (para controlar a profundidade e complexidade da árvore).\n",
    "\n",
    "Min Samples Split: Para controlar o número mínimo de amostras necessárias para dividir um nó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41b7b70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando o GridSearch para DecisionTree ---\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "Melhor F1 para DecisionTree: 0.9340\n",
      "Resultados salvos em: c:\\Users\\USUARIO-PC\\Documents\\GitHub\\MachineLearnig-Classifiacacao\\results\\metrics\\DecisionTree_results.csv\n",
      "Melhores parâmetros DT: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 20}\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt_params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 10, 20]\n",
    "}\n",
    "\n",
    "# Chama a função que está no arquivo .py\n",
    "dt_grid = run_classification_experiment(dt_model, dt_params, X, y, 'DecisionTree')\n",
    "\n",
    "print(f\"Melhores parâmetros DT: {dt_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16660c",
   "metadata": {},
   "source": [
    "## 2. K-Nearest Neighbors (KNN)\n",
    "\n",
    "O KNN classifica instâncias com base na proximidade com exemplos vizinhos. É sensível à escala dos dados (já tratada na etapa de pré-processamento). Testaremos:\n",
    "\n",
    "N Neighbors (k): 3, 5, 7, 9, 11 (número de vizinhos).\n",
    "\n",
    "Weights: Uniforme (todos têm peso igual) vs Distance (vizinhos mais próximos têm maior influência).\n",
    "\n",
    "Metric: Euclidiana vs Manhattan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b7a7e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando o GridSearch para KNN ---\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "Melhor F1 para KNN: 0.9077\n",
      "Resultados salvos em: c:\\Users\\USUARIO-PC\\Documents\\GitHub\\MachineLearnig-Classifiacacao\\results\\metrics\\KNN_results.csv\n",
      "Melhores parâmetros KNN: {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "knn_grid = run_classification_experiment(knn_model, knn_params, X, y, 'KNN')\n",
    "\n",
    "print(f\"Melhores parâmetros KNN: {knn_grid.best_params_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
