{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 01 - Exploração e Limpeza de Dados\n",
    "Este notebook realiza a **análise exploratória dos dados (EDA)** e o **pré-processamento inicial** do dataset *Fetal Health Classification*.\n",
    "As etapas incluem:\n",
    "\n",
    "1. Carregamento e inspeção do dataset bruto  \n",
    "    - Remoção de colunas não utilizáveis  \n",
    "    - Separação entre variáveis preditoras e alvo  \n",
    "2. Análise exploratória (EDA)\n",
    "   - Verificação de tipos, estatísticas, duplicatas e ausentes\n",
    "   - Histogramas\n",
    "   - Boxplots\n",
    "   - Correlação\n",
    "   - Investigação de outliers\n",
    "3. Normalização e salvamento do dataset\n",
    "   - Salvamento do scaler com `StandardScaler`\n",
    "   - Salvamento do dataset processado"
   ],
   "id": "621d6800b2411190"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Imports das funções utilitárias\n",
    "from src.preprocessing import (load_raw_dataset, remove_columns, split_features_target, plot_histograms, plot_target_distribution, \n",
    "                               plot_boxplots, plot_correlation_matrix,find_outliers_iqr , fit_and_save_scaler, save_processed_dataset)"
   ],
   "id": "3766efebc3daf4a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Carregamento e inspeção do dataset bruto",
   "id": "264ee76ca1bbe894"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = load_raw_dataset(\"../data/raw/fetal_health.csv\")\n",
    "print(f\"Linhas: {df.shape[0]}, Colunas: {df.shape[1]}\")\n",
    "df.head()"
   ],
   "id": "ba3bbbd7212b0920",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Sobre o Dataset\n",
    "\n",
    "Este dataset contém 2.126 registros extraídos de exames cardiotocográficos (CTG), utilizados para monitorar a saúde fetal durante a gestação. \n",
    "Existem 21 features e uma coluna alvo. As features representam medidas fisiológicas. Entre elas:\n",
    "\n",
    "- Indicadores derivados do sinal de batimentos cardíacos fetais (FHR) e contrações uterinas:\n",
    "    `baseline value`, `accelerations`, `fetal_movement`,`uterine_contractions`, etc.\n",
    "\n",
    "- Indicadores de variabilidade:  \n",
    "  `abnormal_short_term_variability`, `mean_value_of_short_term_variability`, etc.\n",
    "\n",
    "- Variáveis estatísticas baseadas no histograma do FHR:\n",
    "  `histogram_width`, `histogram_min`, `histogram_max`,  \n",
    "  `histogram_mode` etc.\n",
    "\n",
    "### Variável Alvo:\n",
    "- `fetal_health`: 1 (Normal), 2 (Suspeito) e 3 (Patológico)\n",
    "\n",
    "Mais informações sobre o dataset estão documentadas em [Documentação do dataset](../data/README.md)\n",
    "\n",
    "Como não existe coluna de ID e todas as features são numéricas e apropriadas para modelagem, nenhuma variável precisa ser removida nesta etapa de pré-processamento.\n",
    "\n",
    "Mantivemos todas as features durante o pré-processamento. Mesmo que algumas pareçam muito correlacionadas, como: `several_decelerations` e \n",
    "`prolongued_decelerations`. Além de outras que serão citadas ao logo deste notebook.\n",
    "A possível seleção/exclusão de variáveis será analisada, com validação cruzada e métricas apropriadas, apenas nas fases de modelagem. Evitando \n",
    "análise unicamente por intuição (heurística)."
   ],
   "id": "8758b7e4711c040a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Conversão de dados\n",
    "\n",
    "Há um detalhe importante, percebe-se que o alvo, classes, está como ``float64``. Porém, a mesma é categórica, por isso, será feito o `cast` para `int64`"
   ],
   "id": "81a422481984f3c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['fetal_health'] = df['fetal_health'].astype('int64')",
   "id": "31ee1a0f64a9df65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Separação entre features e alvo\n",
    "\n",
    "Separar as variáveis preditoras da variável alvo é útil na fase de exploração, pois:\n",
    "\n",
    "- evita misturar os atributos de entrada com a classe alvo;\n",
    "- facilita a visualização (histogramas, boxplots, correlação);\n",
    "- permite identificar outliers e distribuições apenas nas features;\n",
    "- prepara a base para o pré-processamento e para a modelagem futura.\n",
    "\n",
    "É uma separação é apenas organizacional."
   ],
   "id": "ebde379b0a273a9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "feature_df, target = split_features_target(df, target='fetal_health')",
   "id": "32e069ae4b74e610",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Análise exploratória (EDA)",
   "id": "49e3509328991c84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Ausência de valores ausentes e duplicados\n",
    "\n",
    "O dataset não possui valores ausentes. Portanto, não será necessário imputação de dados.  \n",
    "Porém, há dados duplicados, 13 no total. Como é um dataset fisiológico derivado de exames CTG, as duplicatas não têm significado clínico, podemos\n",
    " entendê-las como repetições do arquivo original.\n",
    "Além de poderem enviesar certos modelos, principalmente KNN, Naive Bayes e Redes Neurais, Não há razão para mantê-los."
   ],
   "id": "9bc292d386ec5632"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dados faltosos e duplicados\n",
    "print(\"\\nLinhas duplicadas:\", df.duplicated().sum())\n",
    "\n",
    "print(\"\\nValores ausentes:\")\n",
    "print(feature_df.isnull().sum())"
   ],
   "id": "adb98142b882f79a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Removendo as duplicatas\n",
    "df = df.drop_duplicates()"
   ],
   "id": "70ad0f4d02066cbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tipos de dados\n",
    "\n",
    "Todas as variáveis do dataset são numéricas compostas de valores contínuos (`float`).  Logo não será necessária codificação categórica.\n"
   ],
   "id": "3edc93128b8d460b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Tipos de dados:\")\n",
    "print(feature_df.dtypes)"
   ],
   "id": "2d26e5b3ef98e006",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Análise das Distribuições (Histogramas)\n",
    "\n",
    "Com a predominância dos dados numéricos, serão utilizados histogramas, já que permitem visualizar a distribuição das mesmas da melhor forma.  \n",
    "Vemos que as variáveis apresentam comportamentos estatísticos bastante distintos: \n",
    "Algumas features possuem distribuição altamente concentrada em torno de um único valor, como ``fetal_movement`` e ``severe_decelerations``, onde a\n",
    " maioria dos registros está próxima de zero.\n",
    "Já outras, como as variáveis de histogramas são mais dispersas, ainda que possuam assimetria para a esquerda ou direita. \n",
    "Mais detalhes da análise dos histogramas pode ser encontradas no [artigo.](../reports/artigo.pdf) "
   ],
   "id": "cfd936f0820390b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_histograms(feature_df)",
   "id": "f6c4e68dafec4136",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Boxplots e análise de outliers\n",
    "\n",
    "Os boxplots são uma ótima ferramenta de analisar, visualmente, a presença de outiliers. Aqui revelam a presença de outliers principalmente nas\n",
    " variáveis que apresentam distribuição concentrada em torno de um único valor (exemplo: `fetal_movement`, `pronlogued_decelerations`).  \n",
    "Esses valores extremos são esperados e representam eventos reais, como picos de casos ou hospitalizações.  \n",
    "Por isso, optou-se por manter os outliers no dataset.\n"
   ],
   "id": "74c2d75e21f5cc2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_boxplots(feature_df)",
   "id": "e6024546651dce37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Análise de Outliers (IQR)\n",
    "\n",
    "Foi aplicado a técnica do Intervalo Interquartil (IQR) para identificar valores extremos nas variáveis numéricas.  \n",
    "Observa-se que várias features apresentam um grande número de outliers, especialmente nas variáveis cujo valor típico é muito próximo de zero.\n",
    "Mas isso não é um ruído do dataset, muito pelo contrário, alores isolados representam eventos clínicos raros, como:\n",
    "\n",
    "- movimentos fetais mais intensos,\n",
    "- desacelerações severas,\n",
    "- ou alterações abruptas no padrão de variabilidade cardíaca.\n",
    "\n",
    "Por isso, decidiu-se manter esses outliers, pois eles carregam informação importante e refletem fenômenos reais, sendo essenciais para uma modelagem\n",
    " fiel e para o desempenho dos modelos.\n",
    " \n",
    "Vemos a quantidade de outiliers por coluna a seguir, as colunas que não aparecem não os possuem, sendo elas: `baseline value`, \n",
    "`abnormal_short_term_variability`, `histogram_width`, `histogram_min` e `histogram_tendency`. \n"
   ],
   "id": "4c0bfb49c3647ada"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Quntidade de outiliers por feature\n",
    "\n",
    "for col in df.columns:\n",
    "    outliers, lower, upper = find_outliers_iqr(df[col])\n",
    "    if outliers.count() == 0:\n",
    "        continue\n",
    "    print(f\"{col}: {outliers.count()} outliers\")\n"
   ],
   "id": "103927c062caae6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Distribuição da variável alvo\n",
    "\n",
    "Para a variável alvo `fetal_health`, utilizamos um gráfico de barras (countplot), pois ela é categórica.  \n",
    "Observa-se um forte desbalanceamento, com predominância da classe 1 (“Normal”).  \n",
    "Esse desbalanceamento é comum em dados clínicos e será considerado na fase de modelagem."
   ],
   "id": "f892b633cff8cd77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_target_distribution(target)",
   "id": "d820d08d452558cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Matriz de Correlação\n",
    "\n",
    "A matriz de correlação apresenta um padrão complexo.  \n",
    "Embora exista a diagonal principal (correlação perfeita da variável consigo mesma), a maior parte das correlações entre features permanece **baixa**, variando entre aproximadamente **−0.25 e +0.25**, indicando dependência linear fraca ou inexistente.\n",
    "\n",
    "Entretanto, observamos alguns grupos bem definidos de correlações mais fortes, especialmente entre as variáveis derivadas do histograma:\n",
    "\n",
    "- **histogram_mean**, **histogram_median** e **histogram_mode** apresentam correlação quase perfeita entre si (≈ 1), refletindo que todas medem \n",
    "características semelhantes da distribuição dos batimentos cardíacos fetais.\n",
    "- Outras variáveis do histograma, como **histogram_min**, **histogram_max** e **histogram_number_of_peaks**, também exibem correlações moderadas a altas (acima de 0.75, ou abaixo de -0.75), o que é esperado, pois essas medidas são estatisticamente relacionadas.\n",
    "\n",
    "Fora desse conjunto, o restante das features apresenta correlação fraca, indicando que muitas variáveis carregam informação distinta e não redundante.\n",
    "\n",
    "Esse comportamento tem duas implicações importantes:\n",
    "\n",
    "1. **Alguns grupos de variáveis são redundantes** (especialmente as baseadas em histogramas), podendo influenciar modelos sensíveis à multicolinearidade como a Regressão Logística e Redes Neurais.\n",
    "2. **As demais variáveis são amplamente independentes**, o que favorece algoritmos que assumem independência entre features, como o Naive Bayes, que \n",
    "presume a idepêndencia das features.\n",
    "\n",
    "A presença de um pequeno grupo de variáveis altamente correlacionadas não compromete a modelagem, mas poderá impactar alguns algoritmos durante a \n",
    "avaliação, como foi citado, especialmente nos coeficientes de modelos lineares. Esse ponto será retomado no Notebook de modelagem."
   ],
   "id": "8719ab3534cc82d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_correlation_matrix(feature_df)",
   "id": "6c2fa17ad0050257",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Normalização e salvamento do dataset",
   "id": "c170f467543ed1c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalização dos Dados\n",
    "\n",
    "A normalização é uma etapa importante quando utilizamos modelos que dependem de distâncias ou assumem variáveis escaladas de forma semelhante.\n",
    "Optou-se por utilizar o **StandardScaler**, que transforma cada feature para média 0 e desvio padrão 1.\n",
    "\n",
    "Essa escolha é adequada para modelos que serão utilizados, como:\n",
    "\n",
    "- KNN (baseado em distância)\n",
    "- Regressão Logística (otimização mais estável)\n",
    "- MLP (rede neural converge mais rápido)\n",
    "- Naive Bayes Gaussiano (assume que seja uma distribuição normal)\n",
    "\n",
    "A normalização é ajustada apenas nos **dados de treino**, dentro do procedimento de validação cruzada, para evitar **data leakage**.\n",
    "Aqui ajustamos (`fit`) o scaler apenas para salvá-lo e disponibilizá-lo para a etapa de modelagem, para um posssível teste de baseline. Além de salvar os transformers, uma boa prática em ML/AI.\n",
    "\n",
    "Outras normalizações existem como o ``Min-Max``, scaling que transforma os valores para o intervalo [0, 1].  \n",
    "Apesar de ser útil em alguns casos, ele é muito sensível a outliers — e este dataset possui outliers nas variáveis de contagem (casos e hospitalizações).\n",
    "\n",
    "O StandardScaler é mais robusto para esse cenário, pois, não \"colapsa\" valores por causa de outliers e dá uma escala bem distribuída para variáveis que podem assumir valores amplos.\n",
    "\n",
    "Por isso, o StandardScaler foi escolhido."
   ],
   "id": "1a70aa7ab7b75581"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Salvando o dataset processado\n",
    "\n",
    "Após normalização e ajustes, salvamos:\n",
    "\n",
    "- o dataset processado (`fetal_health_processed.csv`)\n",
    "- o scaler treinado (`preprocessor.joblib`)\n",
    "\n",
    "Esses arquivos serão usados pelos notebooks de [modelagem](02_modeling.ipynb) e [avaliação](03_evaluating.ipynb).\n"
   ],
   "id": "183c2d36015b951f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T11:11:11.951882Z",
     "start_time": "2025-11-26T11:11:11.945371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "# Caminhos\n",
    "processed_dir = \"../data/processed\"\n",
    "scaler_path = os.path.join(processed_dir, \"preprocessor.joblib\")\n",
    "processed_csv_path = os.path.join(processed_dir, \"fetal_health_processed.csv\")\n",
    "\n",
    "# Salvando os dados\n",
    "# scaler = fit_and_save_scaler(feature_df, save_path=scaler_path)\n",
    "# save_processed_dataset(df, processed_csv_path)"
   ],
   "id": "80c974ff88bd649f",
   "outputs": [],
   "execution_count": 44
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
